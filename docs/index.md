
Introduction to deep learning techniques for NLP. The goals of this course are:  

- To understand the structure of neural networks  
- To be familiar with central concepts in deep learning for NLP  
- To know the most common deep learning models applied in NLP  
- To implement your own deep learning models using the pytorch library  

## News: 

- Moodle page up and running  
- Slides and other materials available [here](https://github.com/compling-potsdam/sose20-deep-nlp/tree/master/docs/materials) after each session 

## Practical Info

Sharid Loáiciga  
<loaicigasanchez@uni-potsdam.de>  

Tuesdays 4:15pm - 6:00pm  
Runs from 21.04.2020 to 21.07.2020  
(Room 2.14.0.32) ONLINE until further notice  


| Session  | Date  | Content  | Preparation Material  | Release | Due    | 
|---|---|---|---|---|---|
| 1  | 21.04.2020  | Introduction  |   YG ch.2       |       |  reaction paragraph not required    |
| 2  | 28.04.2020  | Revision of linear algebra & statistics ; Pytorch basics | YG ch.2; M&S chs. 2,3,12  | A1  | rp + set up |
| 3  | 05.05.2020  | Feed forward networks (FFNs)   |  YG chs. 3&4; Rao ch3; M&S ch.5; [derivatives](http://cs231n.stanford.edu/handouts/derivatives.pdf); [backpropagation](http://colah.github.io/posts/2015-08-Backprop/) |   | rp  |
| 4  | 12.05.2020 | QA + Word embeddings 1 | [video](https://www.youtube.com/watch?v=kEMJRjEdNzM); YG ch.8  |  | rp + A1  |
| 5  | 19.05.2020 |   Word embeddings 2 + intro to projects   | stanford [a1](http://web.stanford.edu/class/cs224n/assignments/a1.zip)   | A2  |---|
| 6  |  26.05.2020 | NNs training                   | YG ch.5  |               |  rp |
| 7  |  02.06.2020 | no zoom meeting   | --  |   --   |  A2   |
| 8  |  09.06.2020 | Recurrent neural networks (RNNs)   | [Intro to LMs](https://web.stanford.edu/~jurafsky/slp3/3.pdf), [ML chapter](http://www.deeplearningbook.org/contents/rnn.html), [blog post1](http://karpathy.github.io/2015/05/21/rnn-effectiveness/), [blog post2](http://norvig.com/chomsky.html). One book + one blog necessary for rp. | A3  | rp | 
| 9  |  16.06.2020    | Special RNNs (gradient issues,, stacked, GRUs, LSTMs) |   |   |   |
| 10  |            | |   |  |rp + A3  |
| 11  |   | Super special RNNS (conditioned RNNs aka seq2seq models) |   |   |  rp + group contracts + pick project topic |
| 12  |   | Convolutional NNs (CNNs)  |   |   |rp    |
| 13  |   | QA  |   |   | any late assignments  |
| 14  |   | Project proposal presentations  |   |   |   |


## Reading material 

**\[YG\]** Goldberg, Yoav (2017).  Neural Network Methods in Natural Language Processing. Morgan & Claypool Publishers.

**\[M&S\]** Moore, Will H. & David A. Siegel (2013). A Mathematics Course for Political and Social Research. Princeton University Press.  
[Videos here](https://www.youtube.com/channel/UCrA2SLUKnV6yjdgIfDwFeGg/playlists).

**\[DR\]** Rao, Delip & Brian McMahan (2019). Natural language processing with PyTorch: build intelligent language applications using deep learning. Beijing: O'Reilly.  IMPORTANT: please choose 'read online' in order not to block the book. 

All jupyter notebooks used in this course come from the companion repository by Rao & McMahan.

⭐️**All the books are available through the UP network.**

## Examination  

The following aspects are needed to pass the course:  

 - reaction paragraph for each pack of preparation material assigned per week
 - 3 assignments completed (A1, A2, A3)
 - project work: [presentation of a project proposal and written report of completed project](https://compling-potsdam.github.io/sose20-deep-nlp/final_project/instructions). 

**All hand in deadlines refer to the day at 11:00pm**

### Late policy for assignments 

There will be a second and final deadline for late submissions on July 14, 11:00pm. If you fail to meet the first deadline for reaction paragraphs or assignments, you may use this second deadline. 

